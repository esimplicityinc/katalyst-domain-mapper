---
id: US-069
title: "Scan Repositories with AWS Bedrock Models"
persona: PER-002
status: complete
capabilities:
  - CAP-004
use_cases: []
acceptance_criteria:
  - "AWS Bedrock is configurable as an LLM provider via environment variable"
  - "Scan quality and output format are equivalent to the direct Anthropic API"
  - "Docker entrypoint handles Bedrock authentication and region configuration"
---

# US-069: Scan Repositories with AWS Bedrock Models

**As a** Platform Engineer,
**I want to** run FOE scans using AWS Bedrock as the LLM provider,
**so that** I can use my organization's existing AWS infrastructure and compliance controls instead of requiring a direct Anthropic API key.

## Context

The FOE scanner originally only supported the direct Anthropic API for its AI-powered analysis. Many enterprise teams operate within AWS and prefer — or are required — to route AI traffic through AWS Bedrock for cost management, access controls, audit logging, and data residency compliance. The scanner now supports Bedrock as an alternative LLM provider, configurable via environment variables. The Docker entrypoint detects the provider setting and configures authentication accordingly. Scan quality is equivalent regardless of which provider is used, since the underlying model capabilities are the same.

## Road Items

- N/A (Infrastructure enhancement, no dedicated road item)

## Acceptance Criteria

1. AWS Bedrock is configurable as an LLM provider via an environment variable (e.g., `LLM_PROVIDER=bedrock`)
2. Scan quality and JSON output format are equivalent to the direct Anthropic API — same schema, same scoring
3. Docker entrypoint handles Bedrock authentication (AWS credentials, region) and passes configuration to the scanner agents
